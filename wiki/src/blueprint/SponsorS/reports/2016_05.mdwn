[[!meta title="Tails May 2016 report"]]

[[!toc levels=2]]

<div class="caution">
<strong>Deadline: 2016-06-05</strong>
</div>

<div class="note">
Deliverable identifiers and descriptions are not free-form: they must
be copy'n'pasted as-is from the proposal sent to the sponsor.
</div>

[Last month's activity on Redmine](https://labs.riseup.net/code/projects/tails/issues?query_id=208)
can be helpful.

This reports covers the activity of Tails in May 2016.

Everything in this report is public.

# A. Replace Claws Mail with Icedove

## A.n. description of subsection

- A.n.m. description of deliverable: ticket numbers

  status summary:

  * what was done
  * what is the outcome (how it makes Tails better)
  * what was not done, and why

# B. Improve our quality assurance process

## B.3. Extend the coverage of our test suite

### B.3.11. Fix newly identified issues to make our test suite more robust and faster

- Robustness improvements

  The previous two months' work on Chutney ([[!tails_ticket 9521]])
  and Dogtail ([[!tails_ticket 10721]]) has started to pay off; since
  mid-April over 60 scenarios have been made reliable and enabled in
  Tails' development branch. The vast majority of these comes from
  switching the tests from using the real network to a private one run
  by Chutney. The reason for this is that existing tests automatically
  get the benefits from Chutney without modification, except in a few
  edge cases, whereas Dogtail requires the problematic parts of tests
  to be rewritten under a completely different paradigm.

  With the automated test suite's problems due to "transient network
  issues" solved thanks to Chutney, we should now be able to focus our
  attention on fixing "glitches when interacting with graphical user
  interfaces" using Dogtail, so the final month of this contract will
  be spent on rewriting problematic tests using it.

### B.3.14. Write tests for incremental upgrades ([[!tails_ticket #6309]])

  This test has been carefully designed in such a way that it can be
  applied on *any* Tails version -- normally these upgrades can only
  be applied to a specific Tails version. This was the main difficulty
  in this work, and with that solved, the implementation is simple,
  and will be finished in early June.

## B.4. Freezable APT repository

The work we have done has been reviewed, merged into the main Tails
development branch, and successfully used while preparing Tails
2.4~rc1. Unsurprisingly, we had to fix a couple small bugs that
earlier testing had not discovered, but all in all we're very
satisfied by how the whole thing work: it has been very solid and
performed pretty well so far. We are proud to point to the first ever
tagged snapshot, that contains only the set of packages needed for
building Tails 2.4~rc1, and the corresponding source code:
<http://tagged.snapshots.deb.tails.boum.org/2.4-rc1/>.

Now, let's dive into the details:

- B.4.3. Centralize and merge the list of needed packages

  As [[explained previously|contribute/reports/SponsorS/2015/2016_03#index4h2]],
  the original definition of this deliverable doesn't make sense
  anymore, so here we are reporting about what now replaces it:

  * Allow storing APT snapshots longer than the default when needed:
    the code was reviewed, merged, and successfully used in production
    while preparing Tails 2.4~rc1, so this is completed.

  * Freeze and unfreeze the APT snapshots used by a branch when
    needed: the code and corresponding documentation were reviewed,
    merged, and used in production, so this is completed.

  So we're happy to report that deliverable B.4.3 has been completed
  in May.

- B.4.5. Implement processes and tools for importing and freezing those packages ([[!tails_ticket 6299]], [[!tails_ticket 6296]])

  As [[said last month|contribute/reports/SponsorS/2015/2016_04]], the
  last remaining bits here are about handling some consequences on
  this system:

  * Garbage collection of APT repository snapshots: this was deployed
    in production and works fine.

  * Manage a very custom configuration for `apt-cacher-ng`: this was
    reviewed, merged, and used in production since then.

  * Manage `reprepro`'s database growth: we checked the actual data
    in our production environment and realized that there is actually
    no problem to be solved here; since we have enabled garbage
    collection, the database has not grown at all.

- Miscellaneous follow-ups

  We have submitted upstream three branches that improve the Puppet
  module we use to manage `reprepro` in ways that made it compatible
  with the needs of our freezable APT repository.

  By the end of July, we will also do some polishing in various areas:

  * Polish a bit the design documentation for the entire setup
    ([[!tails_ticket 11447]]).

  * If needed, write helper tools for freeze exceptions
    ([[!tails_ticket 11448]]).

  * Investigate a weird issue we have identified, when a package is
    not removed from our time-based APT snapshots, while it should be
    ([[!tails_ticket 11496]]).

# C. Scale our infrastructure

## C.1. Change in depth the infrastructure of our pool of mirrors

The new mirror pool is now used by Tails Upgrader, by users who
download Tails without using our Download And Verification Extension
for Firefox (aka. DAVE), for any download that is not supported by
DAVE (e.g. release candidates), and for downloads started from a web
browser that has JavaScript disabled. So, in summary two of the use
cases of this work are covered already, and only the "downloading with
DAVE" use case is left to complete.

- C.1.2. Write & audit the code that makes the redirection decision from our website ([[!tails_ticket 8639]], [[!tails_ticket 8640]], [[!tails_ticket 11109]])

  * `mirror-dispatcher.js`: we are still waiting for the auditor to do
    a final security review.

  * Download And Verification Extension for Firefox: we have made some
    progress on the implementation, DAVE can now use the mirror pool. However,
    we still need to ensure that, once a mirror is deleted, DAVE will be able to
    pursue a download that has already started from another mirror. 
    We've coordinated with the person who will do the code review to ensure 
    he will be available when we need it. This deliverable shall be completed
    for the next milestone.

- C.1.4. Communicate with each mirror operator to adapt their configuration ([[!tails_ticket 8635]], [[!tails_ticket 11079]])

  This deliverable is completed:

  * All mirrors have now implemented the changes we requested.

  * We have sent a call for mirrors to a number of fast mirror
    operators, and we already have 7 more mirrors. We will pursue this
    effort in June, even though we have already reached the goals we
    had set: we expected to have at least 30 mirrors in the pool once
    the new infrastructure was ready, and 35 mirrors 3 months later,
    and we already have 36 active mirrors as of May 31.

- C.1.6. Adjust download documentation to point to the mirror pool dispatcher's URL ([[!tails_ticket 8642]], [[!tails_ticket 11329]], [[!tails_ticket 10295]])

  This was deployed to production: all links pointing to our mirror
  pool now use the new redirection system.

  So, this deliverable is now completed.

- C.1.7. Adjust update-description files for incremental upgrades ([[!tails_ticket 11123]])

  We have adjusted the code of Tails Upgrader to use the new mirror
  pool. This code has been merged, and is now used by Tails Upgrader
  in production (starting with Tails 2.4~rc1), so this deliverable is
  completed as well.

- C.1.8. Clean up the remainers of the old mirror pool setup ([[!tails_ticket 8643]], [[!tails_ticket 11284]])

  This is now only blocked by the work that is in progress on DAVE
  (C.1.2).

## C.4. Maintain our already existing services

XXX: bertagaz, please review/complete

- C.4.6. Administer our services upto milestone VI

  We kept on answering the requests from the community and taking care
  of security updates.

  We noticed that old Puppet reports were not cleaned up as they
  should on our infrastructure, so we fixed this and submitted a merge
  request to the Puppet module we use to manageâ€¦ Puppet itself
  ([[!tails_ticket 11468]]).

  We noticed that our four newest virtual machines used to
  continuously run our automated test suite on all ISO images built by
  our Jenkins instance (B.2) did not reboot as intended between test
  suite runs. We investigated the root cause of the problem, and fixed
  it ([[!tails_ticket 11467]]).

  We ported everything that made sense to, in our Puppet
  infrastructure, to use [Hiera](https://github.com/puppetlabs/hiera).
  Not only this simplified a lot how we manage systems, but more
  importantly, this allowed us to release quite a bit more of our
  Puppet code. This is part of our strategy to treat infrastructure as
  code, and to enable more people to contribute to it without needing
  any special credentials.

  We streamlined email reporting from failed cronjobs across our
  infrastructure, to ensure we don't miss problems.

  We did lots of refactoring and miscellaneous clean ups in our Puppet
  code. Sprint cleaning!

# E. Release management

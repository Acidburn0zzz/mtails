[[!meta title="Improvements to the donation process"]]

Calendar until the campaign:

  - Week 32, Aug  3: summit
  - Week 33, Aug 10: team member unavailable
  - Week 34, Aug 17: team member unavailable
  - Week 35, Aug 24
  - Week 36, Aug 31
  - Week 37, Sep  7
  - Week 38, Sep 14
  - Week 39, Sep 21: sajolida unavailable
  - Week 40, Sep 28: sajolida unavailable
  - Week 41, Oct  5: sajolida unavailable
  - Week 42, Oct 12: launch the campaign

I think that we should do, in this rough order:

### Skip any in-person usability tests for now

It's quite time consuming and the Covid situation makes it more
complicated. We can do other things and keep this for next year.

Week 32
-------

### Brainstorm on images with Andrés

Week 33
-------

### Survey lapsed donors

Goals:

* Learn about motivation to better frame our message
* Identify low hanging fruits in how we could steward them better

Week 34
-------

### Add an image to /donate

And work on how to put the image on the page.

At some point we should show the draft images to people. This should
be easy to do remotely with a handful of past donors that we know a
bit better and can ask a favor to. We could also skip this testing
step and fallback on A/B testing during the campaign.

### Give some love to /donate/thanks and /donate/canceled

These pages look crap and we don't spend time on them because we don't
see them ourselves. But I think that they are critical and low-hanging
fruits. Some [psychological
foundations](https://www.nngroup.com/articles/peak-end-rule/) for that.

Add to each of them:

* A feedback mechanism, especially on /donate/canceled!
* An image
* Better text

These are things that are better studied in usability tests but they
are so bad right now that it should be easy to agree on possible
improvements while keeping them cheap.

Weeks 35-38
-----------

### Do non-controversial changes on /donate

Since we won't do usability tests and to avoid a situation à la
[[!tails_ticket 16830]], we will limit our changes to:

* Things we agree on easily
* Research-based recommendations from experts
* Things we can A/B test during the campaign

Ideas:

* Add an image.
* Improve "How we spend our money" to tell more about the impact.
* Improve the headline.

### Plan some A/B testing during the campaign (if needed)

Like I did for [[!tails_ticket 16830]], we could do more such things
during the campaign. For example, we could test different images, text,
or controversial changes.

Weeks 42
--------

### Analyze the results of the A/B testing on frequency buttons ([[!tails_ticket 16830]])

Compare the conversion rates between Tor Browser, Tails, and mobile.
I'll be analyzing logs when looking at the results of the A/B testing on
the monthly buttons anyway.

Anything else worth analyzing in the logs?
